


#1. import pandas
import pandas as pd





# 2. read cleaned pickle file from Assignment 2 into "mortality_data" variable
mortality_data = pd.read_pickle("C:/repositories/lis4930/a2/a2_payroll/mortality_cleaned.pkl")





# 3. display first and last 5 rows with one command!
# Note: the following way *only* works in Jupyter Notebooks
# mortality_data
print(mortality_data)





# 4. Use Pandas DataFrame info() Method:
# Prints:
# 1. number of columns
# 2. column labels
# 3. column data types
# 4. memory usage
# 5. range index
# 6. number of cells in each column (non-null values).
mortality_data.info()


# 5. print the following DataFrame attributes: index, columns, size, and shape
print("Index:  ", mortality_data.index)
print("Columns:", mortality_data.columns)
print("Size:   ", mortality_data.size)
print("Shape:  ", mortality_data.shape)





# 6. display first 3 records sorted by DeathRate in ascending order
# Note: sort_values() function sorts in ascending order by default!
print(mortality_data.sort_values('DeathRate').head(3))


# 7. display first 3 records sorted by DeathRate in descending order
print(mortality_data.sort_values('DeathRate', ascending=False).head(3))


# 8. display first 3 records sorted by Year and DeathRate, *both* in ascending order
# Note: major/minor order (left to right). Here, first Year, then DeathRate.
print(mortality_data.sort_values(['Year', 'DeathRate']).head(3))


# 9. display first 3 records sorted by DeathRate and Year, *both* in ascending order
# Note: difference in major/minor sort order
print(mortality_data.sort_values(['DeathRate', 'Year']).head(3))


# 10. display first 5 records sorted (first) by Year (ascending), then DeathRate (descending)
print(mortality_data.sort_values(['Year', 'DeathRate'],
                                 ascending=[True,False]).head())


# 11. display first 5 records sorted (first) by DeathRate (descending), then Year (ascending)
print(mortality_data.sort_values(['DeathRate', 'Year'],
                                 ascending=[False,True]).head())





# 12. display DeathRate mean
print(mortality_data.DeathRate.mean())


# 13. display concatenated string and numeric output
print("DeathRate mean: " + str(mortality_data.DeathRate.mean()))
# or...
# print("DeathRate mean: ", str(mortality_data.DeathRate.mean()))


# 14. Same as above, though formatted to two decimal places
print("DeathRate mean: "
      + str(format(mortality_data.DeathRate.mean(), ".2f")))


# 15. display max AgeGroup and DeathRate values (two columns)
# Note: AgeGroup sorted by *ASCII* values (5>1)--that is, why it is important to zero-fill, when necessary (see below)!
print(mortality_data[['AgeGroup','DeathRate']].max())


# 16. display total numbers (all columns, excluding null values):
print(mortality_data.count())


# 17. using pandas quantile() function, display 50% value of Year column, verify using median() function
# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.quantile.html
print(mortality_data[['Year']].quantile([.5]))
print(mortality_data[['Year']].median())


# 18. Same as above, though, display 50% value of *both* Year *and* DeathRate columns, verify using median() function
print(mortality_data[['Year','DeathRate']].quantile([.5]))
print(mortality_data[['Year','DeathRate']].median())


# 19. Same as above, though, display 10% value of *both* Year *and* DeathRate columns, then 90% value of each, using *one* statement
# quantile values (Example: 10% and 90%):
# 10%: year = 1911.5, and 10% of death rates less than 21.50.
# 90%: year = 2006.5, and 90% of death rates less than 430.85.
print(mortality_data.quantile([.1,.9], numeric_only=True))

# Note: The defualt value of numeric_only in DataFrame.quantitle is deprecated.
# In a future version, it will default to False.
# Select only valid columns or specify the value of numeric_only to silence this warning.


# 20. display cumulative sum of DeathRate values (i.e., each row added to previous row), use cumsum() function
print(mortality_data['DeathRate'].cumsum())


# 21. verify cumsum() function by displaying first 5 records fo DeathRate col
print(mortality_data['DeathRate'].head(5))





# 22. create and display two new columns (i.e., 'Mean' and 'MeanCentered') in DataFrame using column arithmetic
# 'Mean Centered' displays how far from the mean each value is, a constant is subtracted (the mean) from every value of a particular variable--here DeathRate.
# 'centering' refers to the process of subtracting the mean from a variable (usually a predictor)
# 'centering' is important when interpreting group effects of interest
# 'centering' redefines '0 point' for 'predictor' to be whatever value was subtracted (here, the mean). It shifts the scale over, but retains the units.
# Note: Explicit line joining using backslash (\).
# https://docs.python.org/3/reference/lexical_analysis.html#line-structure
mortality_data['Mean'] = mortality_data.DeathRate.mean()
mortality_data['MeanCentered'] = \
    mortality_data.DeathRate - mortality_data.DeathRate.mean()


# 23. print mortality_data DF
# Note: new cols in mortaltiy_data DataFrame
print(mortality_data)





# 24. modify col names, so that col names are treated 'equally,' that is, when being sorted (here, using dictionary)
# inplace set to true in order to replace values in DataFrame
mortality_data.AgeGroup.replace(
    {'1-4 Years':'01-04 Years','5-9 Years':'05-09 Years'},
    inplace=True)





# 25. save prepped DataFrame to pickle file
mortality_data.to_pickle('mortality_prepped.pkl')


# 26. Read prepped DataFrame from pickle file, and print first 5 records
mortality_data = pd.read_pickle('mortality_prepped.pkl')
mortality_data.head()





# 27. display first 2 records (note current indexes)
mortality_data.head(2)


# 28. index 'year' col, then display first two records (note new indexes)
# ***Note:*** indexed columns *cannot* be used as parameters in other methods/functions!
mortality_data = mortality_data.set_index('Year')
mortality_data.head(2)


# 29. reset original index, then dispay first two records (note original indexes)
# inplace set to true to in order to replace values in DataFrame
mortality_data.reset_index(inplace=True)
mortality_data.head(2)


# 30. create multi-index, check validity (i.e., no duplicates), then display first two records (note new indexes)
# set multi-index to 'Year' and 'AgeGroup'
mortality_data = mortality_data.set_index(
    ['Year', 'AgeGroup'], verify_integrity=True)
mortality_data.head(2)


# 31. reset original index (using inplace), then display first two records (note new indexes)
mortality_data.reset_index(inplace=True)
mortality_data.head(2)





# 32. pivot the following DataFrame: index='Year', columns='AgeGroup'
# index: 'Year'
# column to use to make new frame's columns: 'AgeGroup'
# values: all remaining columns to populate new DataFrame's values
# Note: if no 'values' par, uses *all* remaning cols!
# assign resulting DataFrame to 'mortality_wide' variable, then display first 3 records
mortality_wide = mortality_data.pivot(index="Year",columns="AgeGroup")
mortality_wide.head(3)


# 33. pivot the following DataFrame:
# index: 'Year'
# column to use to make new frame's columns: 'AgeGroup'
# values: 'DeathRate'
# assign resulting DataFrame to 'mortality_wide' variable, then display first 3 records
mortality_wide = mortality_data.pivot(index="Year", columns="AgeGroup", values="DeathRate")
mortality_wide.head(3)


# 34. save wide DataFrame to Excel file ('mortality_wide.xlsx')
# Note: *Be careful* saving wide DataFrame to Excel file changes index--must change back (see below)!
mortality_wide.to_excel('mortality_wide.xlsx')


# 35. read saved Excel file and assign to 'mortality_wide' variable, then display first 4 records
mortality_wide = pd.read_excel('mortality_wide.xlsx')
print(mortality_wide.head(4))


# 36. save wide DataFrame to pickle file ('mortality_wide.pkl')
mortality_wide.to_pickle('mortality_wide.pkl')


# 37. read saved pickle file and assign to 'mortality_wide' variable, then display first 5 records
mortality_wide = pd.read_pickle('mortality_wide.pkl')
mortality_wide.head()





# 38. melt following DataFrame: 'mortality_wide'
# id_vars= 'Year'
# value_vars=['01-04 Years', '05-09 Years']
# var_name='AgeGroup'
# value_name='DeathRate'
# assign resulting DataFrame to 'mortality_long' variable, then display first 4 records

mortality_long = mortality_wide.melt(
    id_vars='Year',
    value_vars=['01-04 Years', '05-09 Years'],
    var_name='AgeGroup',
    value_name='DeathRate')
mortality_long.head(4)


# 39. using pandas option_context() function, display 6 rows (first 3 and last 3) and all cols
# Note: option_context() - executes codeblock with set of options that revert to prior settings after execution
# Note: 'None' value for 'display.max_columns' property returns *all* cols.
with pd.option_context(
    'display.max_rows', 6,
        'display.max_columns', None):
    print(mortality_long)





# 40. display first 5 records of 'mortality_data' DF (i.e., prior to aggregation)
mortality_data.head()


# 41. group 'AgeGroup' by mean, and display DF
mortality_data.groupby('AgeGroup').mean()


# 42. group 'Year' by median, and display first 4 records
# Note: see numeric_only=True note above.
mortality_data.groupby('Year').median(numeric_only=True).head(4)


# 43. group 'Year' and 'AgeGroup' by count, and display first 5 records
# Note: only for demo purposes, since there is only 1 record for each group
mortality_data.groupby(['Year', 'AgeGroup']).count().head()


# 44. group 'AgeGroup', then return statistical summary for 'DeathRate' using 'describe()' function
mortality_data.groupby('AgeGroup')['DeathRate'].describe()


# 45. group 'AgeGroup', then using agg() function, aggregate *all* columns using 'mean' and 'median' functions
mortality_data.groupby('AgeGroup').agg(['mean', 'median'])


# 46. group 'AgeGroup', then using agg() function, aggregate only 'DeathRate' column
# using 'mean,' 'median,' 'standard deviation,' and 'unique' functions
mortality_data.groupby('AgeGroup')['DeathRate'].agg(['mean', 'median', 'std', 'nunique'])


# 47. group 'Year', then using agg() function, aggregate only 'DeathRate' column
# using 'mean,' 'median,' 'standard deviation,' 'min,' 'max,' 'variance,' and 'unique functions
mortality_data.groupby('Year')['DeathRate'].agg(['mean', 'median', 'std', 'min', 'max', 'var', 'nunique'])





# 48. pivot 'mortality_data' DataFrame using the following parameters:
# index: 'Year'
# column to use to make new frame's columns: 'AgeGroup'
# values: all remaining columns to populate new DataFrame's values
# Note: if no 'values' par, uses *all* remaining cols!
# after pivoting DataFrame, use plot() function to display line plot (default)
mortality_data.pivot(index='Year',columns='AgeGroup')['DeathRate'].plot()


# 49. display some plot as above by re-indexing mortality_wide DF
# Note: Because, saving wide DataFrame to Excel file changes index--must re-index (see above)!
# Change index back to 'Year'
mortality_wide = mortality_wide.set_index('Year')

# save wide DataFrame to pickle file ('mortality_wide.pkl')
# read saved pickle file and assign to 'mortality_wide' variable,
# then display first 5 records to display new index
mortality_wide.to_pickle('mortality_wide.pkl')
mortality_wide = pd.read_pickle('mortality_wide.pkl')
mortality_wide.head()





# https://www.simplypsychology.org/boxplots.html
# 50. using 'mortality_data' DataFrame, create a box plot (aka "box and whisker plot") for each age group
# Note: box plot displays five-number summary: min, 1st quartile, median (2nd quartile), 3rd quartile, and max.
# Note: interquartile range (IQR) is the "box"
# Note: outliers are *actual* min/max values (data points located outside whiskers of box plot)
mortality_wide.plot.box()


# 51. display line plot for re-indexing mortality_wide DF
# Note: xlabel: 'Year', ylabel: 'Deaths per 100,000', title: 'DeathRate by AgeGroup'
mortality_wide.plot(xlabel='Year', ylabel='Deaths per 100,000', title='DeathRate by AgeGroup')


# 52. using 'mortality_data' DataFrame, group 'AgeGroup', then aggregate only 'DeathRate' column
# using 'mean,' 'median,' and 'standard deviation' aggregate functions, then, plot vertical bar plot (rotate x-axis labels 45 degrees)
mortality_data.groupby('AgeGroup')['DeathRate'].agg(['mean', 'median', 'std']).plot.bar(rot=45)


# 53. same as above using horizontal bar plot
mortality_data.groupby('AgeGroup')['DeathRate'].agg(['mean', 'median', 'std']).plot.barh()


# 54. using 'mortality_data' DataFrame, query the following years: 1900, 1925, 1950, 1975, 2000, group by 'Year',
# then aggregate only 'DeathRate' column using sum() function, and, plot the following graph using pie plot
mortality_data.query('Year in (1900, 1925, 1950, 1975, 2000)').groupby('Year').DeathRate.sum().plot.pie()


# 55. using 'mortality_wide' DataFrame, query the following years: 1900, 1925, 1950, 1975, 2000
# then, create subplots for each of the following age groups: 01-04, 05-09, 10-14, 15-19
# create a 2x2 layout, set sharey par. to True (to turn off y labels on remaining horizontal charts), use figure size of 8"x5" (WxH)
mortality_wide.query('Year in (1900, 1925, 1950, 1975, 2000)').plot.barh(
    title=['Child Mortality: 01-04', 'Child Mortality: 05-09',
           'Child Mortality: 10-14', 'Child Mortality: 15-19'],
    sharey=True, legend=False, subplots=True, layout=(2,2), figsize=(8,5))


# https://pandas.pydata.org/pandas-docs/version/0.25.0/reference/api/pandas.DataFrame.plot.scatter.html
# 56. using 'mortality_data' DataFrame, query the following AgeGroup: 01-04 Years,
# then, plot the following graph using scatter plot, with a color of your choice

# Note, if receiving a color warning, just hit Shift+Enter in this cell
# Appears to be an Anaconda issue, as plot documentation is above.
mortality_data.query('AgeGroup == "01-04 Years"').plot.scatter(x='Year', y='DeathRate', c='Blue')
